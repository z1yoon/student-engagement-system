import os
import io
import logging
import base64
from azure.core.credentials import AzureKeyCredential
from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.ai.vision.face import FaceClient
from azure.ai.vision.face.models import (
    FaceDetectionModel,
    FaceRecognitionModel,
    FaceAttributeType,
)
from db import add_engagement_record, mark_attendance, get_enrolled_students

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load Azure API Credentials from environment variables
FACE_API_ENDPOINT = os.getenv("FACE_API_ENDPOINT", "")
FACE_API_KEY = os.getenv("FACE_API_KEY", "")
VISION_API_ENDPOINT = os.getenv("VISION_API_ENDPOINT", "")
VISION_API_KEY = os.getenv("VISION_API_KEY", "")

if not FACE_API_ENDPOINT or not FACE_API_KEY:
    raise ValueError("Azure Face API credentials are missing!")
if not VISION_API_ENDPOINT or not VISION_API_KEY:
    raise ValueError("Azure Vision API credentials are missing!")

# Initialize Azure Clients
face_client = FaceClient(FACE_API_ENDPOINT, AzureKeyCredential(FACE_API_KEY))
vision_client = ImageAnalysisClient(VISION_API_ENDPOINT, AzureKeyCredential(VISION_API_KEY))

def analyze_image(image_data: str):
    """
    Analyzes the image for engagement and phone usage, and marks attendance.
    image_data: base64 encoded image string (with or without data URI scheme)
    """
    try:
        logger.info("üîç Analyzing image for engagement & attendance...")

        # Decode Base64 Image (remove data URI scheme if present)
        try:
            if "," in image_data:
                image_bytes = base64.b64decode(image_data.split(",")[1])
            else:
                image_bytes = base64.b64decode(image_data)
        except Exception as e:
            logger.error(f"‚ùå Error decoding Base64 image: {e}")
            return {"error": "Invalid base64 image format"}

        # Face & Engagement Detection
        faces_info, recognized_students = detect_faces_with_recognition(image_bytes)

        # Phone Usage Detection
        phone_detected = detect_objects(image_bytes)

        if not faces_info:
            logger.info("‚ö†Ô∏è No faces detected. Skipping analysis.")
            return {"message": "No faces detected."}

        # Process Engagement Data and store each record in the DB
        for face in faces_info:
            student_name = recognized_students.get(face["face_id"], "Unknown")
            gaze = face.get("gaze", "unknown")
            sleeping = face.get("sleeping", False)

            # Mark attendance if the student is recognized
            if student_name != "Unknown":
                mark_attendance(student_name, True, image_data)  # ‚úÖ Mark student as present with image

            add_engagement_record(student_name, phone_detected, gaze, sleeping)

        logger.info(f"‚úÖ Image analysis complete. Phone Detected: {phone_detected}")
        return {
            "message": "Analysis complete",
            "faces": faces_info,
            "recognized_students": recognized_students,
            "phone_detected": phone_detected
        }
    except Exception as e:
        logger.error(f"‚ùå Error analyzing image: {e}")
        return {"error": "Failed to analyze image"}

def detect_faces_with_recognition(image_bytes: bytes):
    """
    Detects faces, extracts attributes for engagement, and matches against enrolled student images.
    """
    try:
        face_attrs = [FaceAttributeType.HEAD_POSE, FaceAttributeType.OCCLUSION]
        enrolled_students = get_enrolled_students()  # ‚úÖ Get stored student images from the database

        with io.BytesIO(image_bytes) as image_stream:
            faces = face_client.detect(
                image_content=image_stream.read(),
                detection_model=FaceDetectionModel.DETECTION03,
                recognition_model=FaceRecognitionModel.RECOGNITION04,
                return_face_id=True,  # ‚úÖ Needed for recognition
                return_face_attributes=face_attrs
            )

        results = []
        recognized_students = {}

        for face in faces:
            face_id = face.face_id
            rect = face.face_rectangle
            attributes = face.face_attributes

            if not attributes:
                logger.warning("‚ö†Ô∏è No face attributes found. Skipping this face.")
                continue

            head_pose = attributes.head_pose
            eye_occluded = attributes.occlusion.eye_occluded

            # Determine focus level based on head pose
            gaze = "focused" if abs(head_pose.yaw) <= 30 and abs(head_pose.pitch) <= 20 else "distracted"
            sleeping = eye_occluded

            # Compare with enrolled student faces
            match_name = match_face_with_students(face_id, enrolled_students)

            if match_name:
                recognized_students[face_id] = match_name  # ‚úÖ Store recognized student

            results.append({
                "face_id": face_id,
                "face_rectangle": {
                    "left": rect.left,
                    "top": rect.top,
                    "width": rect.width,
                    "height": rect.height
                },
                "gaze": gaze,
                "eye_occluded": eye_occluded,
                "sleeping": sleeping
            })

        logger.info(f"‚úÖ Face detection complete. Detected {len(results)} faces.")
        return results, recognized_students
    except Exception as e:
        logger.error(f"‚ùå Error detecting faces: {e}")
        return [], {}

def match_face_with_students(face_id, enrolled_students):
    """
    Compares detected face with enrolled student faces and returns a match if found.
    """
    try:
        enrolled_face_ids = [student["face_id"] for student in enrolled_students]

        # Compare faces using Azure Face API
        matches = face_client.verify_face_to_face(face_id, enrolled_face_ids)

        # Find the best match
        for match in matches:
            if match.confidence >= 0.8:  # ‚úÖ Confidence threshold for recognition
                return next(student["name"] for student in enrolled_students if student["face_id"] == match.face_id)

    except Exception as e:
        logger.error(f"‚ùå Error matching faces: {e}")
    return None

def detect_objects(image_bytes: bytes):
    """
    Detects objects in the image to identify items like phones.
    """
    try:
        with io.BytesIO(image_bytes) as image_stream:
            analysis_result = vision_client.analyze(
                image_data=image_stream.read(),
                visual_features=["Objects"]
            )
        detected_objects = [obj.name.lower() for obj in analysis_result.objects if hasattr(obj, "name")]
        phone_detected = "phone" in detected_objects
        logger.info(f"üì± Phone detection result: {phone_detected}")
        return phone_detected
    except Exception as e:
        logger.error(f"‚ùå Error detecting objects: {e}")
        return False
